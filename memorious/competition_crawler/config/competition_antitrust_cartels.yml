name: competition_1

description: 'a scraper for Antitrusts/Cartels cases'

# schedule: weekly
pipeline:

  init:
    method: sequence
    params:
      start: 40632
      step: -1
      stop: 40630
      # stop : 40393
      #stop : 28841
    handle:
      pass: seed

  seed:
    method: seed
    params:
      url: https://ec.europa.eu/competition/elojade/isef/case_details.cfm?proc_code=1_%(number)s
    handle:
      pass: fetch

  fetch:
    method: fetch
    params:
      # only fetch web (html, xml, text) and documents (doc, pdf etc)
      rules:
        or:
          - mime_group: documents
          - mime_group: web
    handle:
      pass: parse

  parse:
    method: parse
    params:
      # only store web and documents ; currently redundant with fetch params
      store:
        # FIXME find a way to avoid storing "procedure doesn't exist" pages
        or:
          - mime_group: documents
          - mime_group: web
      include_paths:
        # focus on the content panel ; this conveniently excludes the menu bars (top, left...),
        # but also avoids following the "new search" link on the "procedure doesn't exist" pages
        - './/td[@id="content"]'
      meta:
        title: '//div[@id="BodyContent"]/p/span/strong'
        policy: '//h2'
        # TODO parse metadata for companies :
        # <tr><td class="ClassLabelDetail_1">Companies:</td><td class="ClassTextDetail">[. . .]</td></tr>
        # TODO parse metadata for economic activities :
        # <tr><td class="ClassLabelDetail_1">Economic Activity:</td><td class="ClassTextDetail" >[. . .]</td></tr>
        # TODO parse metadata for events (and fetch linked docs) :
        # id. except it has structure : <table class="events">
    handle:
      fetch: fetch
      store: store
  
#  debug:
#    method: inspect

# TODO clean HTML before storing : get rid of menu bars etc
  store:
    # store the crawled documents to a directory
    method: directory
    params:
      path: '/data/results'
